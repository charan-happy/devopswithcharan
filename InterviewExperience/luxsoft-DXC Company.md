Date : 19/06/2025  Time : 1.30-2.30 PM

<details><summary>1. Tell me about yourself</summary></details>
<details><summary>2. Since, you mentioned in your resume that you have reduced deployment time by 30 % justify this statement. How you did and what action you have taken
ğŸ‘¨â€ğŸ’» Context from my actual project:
In my last role, we had a microservices-based application running across multiple environments â€” dev, QA, staging, and prod â€” deployed on Kubernetes (EKS) and Azure AKS clusters.

Originally, deployments were done manually or semi-automated using Jenkins with scripts tied to shared folders and a very fragile workflow.

The deployment time per service was around 12â€“15 minutes, and when multiple services needed updates, we often had downtimes, rollbacks, and sync issues between environments.

ğŸš€ Steps I Took to Reduce Deployment Time by 30%
1. ğŸ” Switched from Script-Based Deployments to GitOps (ArgoCD)
Introduced GitOps using ArgoCD to automate and manage deployments.

Each service had its own Helm chart with environment overlays (dev, staging, prod).

Pushing to the Git branch triggered auto-deployments via ArgoCD.

âœ… Result: No more manual interventions; deployments started happening within seconds of merge.

2. ğŸ§± Optimized Docker Images
Our base images were too heavy (using ubuntu:latest, node images with unnecessary tools).

Switched to minimal images (e.g., alpine, multi-stage builds).

Cleaned up layers, removed unnecessary packages, and added .dockerignore.

âœ… Result: Image build time reduced by ~40%; smaller image = faster pull time on K8s.

3. ğŸ“¦ Parallelized CI Jobs in GitHub Actions
Converted the sequential Jenkins pipelines to GitHub Actions, and used matrix strategy to build/test services in parallel.

Caching used for:

npm and pip dependencies

Docker layer cache using GitHubâ€™s actions/cache and buildx

âœ… Result: CI pipeline time dropped from 10â€“12 min to 4â€“5 min.

4. ğŸ•µï¸â€â™‚ï¸ Implemented Canary Deployments with Helm & Argo Rollouts
Used argoproj/argo-rollouts for progressive delivery.

Only 10% of traffic was routed to new pods initially, with health checks.

Full rollout happened only after health was stable.

âœ… Result: Safer deployments and less downtime; no need for manual approval and rollback unless really needed.

5. ğŸ›‘ Reduced Wait Time via Pre-pulled Images & Node Affinity
Pre-pulled critical service images on nodes with DaemonSet.

Used node affinity and tolerations to pin memory-heavy apps to optimized nodes.

âœ… Result: Reduced cold-start and scheduling delays in Kubernetes.

6. ğŸ“£ Slack Notifications & Webhooks
Integrated GitHub Actions with Slack for deployment success/failure alerts.

Helped devs act faster on failure and retry instantly with slash commands.

âœ… Result: Shorter feedback loops = faster bugfix + redeploy cycles.

ğŸ“Š Impact Measured:
Metric	Before Optimization	After Optimization
Avg Deploy Time (per svc)	12â€“15 minutes	7â€“9 minutes
Downtime per deploy	2â€“4 mins	~0 or near zero
Manual steps	4â€“5 steps	0 (GitOps-based)
Rollbacks/Failures	Weekly	Rare (once/month)

ğŸ” Overall Deployment Time Reduction: ~30â€“40%

ğŸ¯ Tools/Technologies Used
GitHub Actions

ArgoCD

Helm + Argo Rollouts

Kubernetes (EKS + AKS)

Docker (Multi-stage builds, BuildKit)

Slack Webhooks

Trivy & SonarQube (inline security + quality scans)

ğŸ’¬ Final Line (For Interview):
"This wasnâ€™t a one-time fix â€” I treated it like a continuous improvement initiative. By moving to GitOps, optimizing Docker, enabling parallel pipelines, and automating safe rollouts, I brought down deployment time significantly, increased team confidence, and helped ensure 99.9% availability." âœ…


âœ… How do I justify numbers like "30% reduction in deployment time"?
ğŸ§  DevOps is a data-driven role â€” we track metrics like build duration, deployment time, failure rate, recovery time, etc., using tools like Grafana, Prometheus, Jenkins dashboards, GitHub Actions Insights, ArgoCD, and manual logs.

So even though these look exact, theyâ€™re based on real trends and monitoring dashboards â€” not random guesses.

ğŸ” Hereâ€™s how I got to 30% in my project:
Phase	Before Optimization	After Optimization	Source
Docker Build	~5â€“6 min (heavy images)	~2.5â€“3 min (alpine, multi-stage)	GitHub Actions + Docker logs
CI Pipeline	~10â€“12 min	~5â€“6 min (parallel + cache)	GitHub Actions metrics
K8s Deploy	~3â€“4 min rollout with downtime	<1 min rollout with Argo Rollouts	ArgoCD dashboards
Downtime	2â€“4 min (manual rollout)	0â€“10 sec (canary+health checks)	Uptime probe + SLO dashboards

âœ… Deployment time (end-to-end) dropped from ~15 mins to ~9â€“10 mins, which is a 30â€“35% reduction.

ğŸ”§ Tools That Helped Me Measure:
GitHub Actions â†’ Pipeline duration (via Insights tab)

ArgoCD â†’ Deployment history and rollout time

Grafana + Prometheus â†’ HTTP probe latency, app availability

ELK / Loki / CloudWatch Logs â†’ Timestamp logs of deployments

Slack Notifications â†’ Time between deployment start and success alert

ğŸ§‘â€ğŸ’¼ What to Say in an Interview:

â€œI tracked our average deployment time using GitHub Actions Insights and ArgoCD dashboards over a 2-month period. After switching to GitOps, optimizing Docker builds, and enabling parallel jobs, we saw a consistent drop in deployment time â€” from an average of 14â€“15 minutes to around 9 minutes. Thatâ€™s how I confidently state we achieved about a 30% improvement.â€

</details>

<details><summary>3. You mentioned 99.9% uptime and costoptimization in aws cloud ? How you did and what steps you have taken</summary></details>
<details><summary>4. How you will solve terraform drift issues ?</summary>Use terraform plan to detect drift

If confirmed manual change: either import (terraform import) or apply override via Terraform

If unwanted, recreate state using terraform state rm/add

</details>
<details><summary>5. What does terraform plan will do ?</summary>It shows what changes Terraform will make before applying. Acts like a dry-run. Helps avoid unintentional infra modifications.</details>
<details><summary>6. how will you resolve manual changes  ex: u wanted to create 1 extra instance w.r.to. existing resources and when u do terraform plan u are able to see 2 instances. How will you fix it ?</summary>Either terraform import that manual instance into state

Or delete the manual one and let Terraform manage it

Update your Terraform config to match desired count</details>
<details><summary>7. what grep and regular expressions and how will they help ?</summary>grep: search for patterns in files

RegEx helps search complex patterns (IP, error codes, dates)

Example:

bash
Copy
Edit
grep -E "^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$" file.txt  # Match IPs
</details>
<details><summary>8. what is vertical and horizontal scaling and which one is good ?</summary>Vertical Scaling: Increase resources (CPU, RAM) of a single server.

ğŸŸ¢ Easy to implement

ğŸ”´ Limited by hardware limits

Horizontal Scaling: Add more servers/nodes

ğŸŸ¢ Scales better, more fault-tolerant

ğŸ”´ Needs load balancers, distributed systems design

Horizontal scaling is better for cloud-native apps.</details>
<details><summary>9. what is docker , why docker ?</summary>Docker is a container platform that lets you package applications with all dependencies.

Why Docker:

Consistency across environments

Lightweight (no full OS like VMs)

Fast startup

Ideal for microservices and CI/CD</details>
<details><summary>10. is this ip correct ? 1.9.142.145</summary>Yes, it is a valid public IPv4 address.</details>
<details><summary>11. what is DHCP</summary>Dynamic Host Configuration Protocol â€“ assigns IP addresses to devices dynamically from a pool. Saves manual effort in IP assignment.</details>
<details><summary>12. what is DNS</summary>Domain Name System â€“ translates human-readable domain names (like google.com) to IP addresses.</details>
<details><summary>13. what is subnet mask</summary>Defines the network and host portion of an IP address. Used to determine routing boundaries in networking (e.g., 255.255.255.0 for Class C).

</details>
<details><summary>14. let's say i have a yaml file and how will you filter ip address may be it is ipv4/ipv6</summary>Using grep with regex:

bash
Copy
Edit
grep -Eo '([0-9]{1,3}\.){3}[0-9]{1,3}' myfile.yaml
For IPv6 (basic):

bash
Copy
Edit
grep -Eo '([a-f0-9:]+:+)+[a-f0-9]+' myfile.yaml</details>
<details><summary>15. image pullback off ? how will u fix it</summary>Causes:

Wrong image name/tag

Private repo without credentials

Network issues

Fixes:

Check kubectl describe pod

Verify image exists in registry

If private, create imagePullSecret and attach it to the pod/service account</details>
<details><summary>16. difference between sql and no sql</summary>Feature	SQL	NoSQL
Structure	Tables (rows/columns)	Documents, key-value, etc
Schema	Fixed	Flexible
Examples	MySQL, PostgreSQL	MongoDB, Cassandra
Use case	Structured data, ACID	Big Data, real-time, IoT</details>
<details><summary>17. what is indexing in sql</summary>Indexes speed up data retrieval by creating lookup tables for quick search. Example:

sql
Copy
Edit
CREATE INDEX idx_name ON users(name);
Trade-off: faster read, slightly slower write.</details>
<details><summary>18. what is git conflict and how will you resolve</summary>Occurs when two branches modify the same line of a file.

Steps:

Git will mark conflict sections (<<<<<<<)

Manually edit and choose correct content

git add .

git commit</details>
<details><summary>19. what are different deployment models in kubernetes</summary>Recreate â€“ Stops old version before starting new

RollingUpdate â€“ Default; gradually replaces pods

Blue-Green â€“ Deploy to a separate environment, switch traffic

Canary â€“ Gradually expose to users in phases</details>
<details><summary>20. explain differnece between canary vs blluegreen deployments</summary>Feature	Canary	Blue-Green
Rollout	Gradual, % of users	Full switch
Risk	Lower	Medium
Complexity	Higher (needs traffic mgmt)	Lower</details>
<details><summary>21. why we need recreate ?</summary>Use when:

Old version and new version canâ€™t coexist

DB schema changes

Port conflicts</details>
<details><summary>22. Difference between paas and saas give examples</summary>PaaS (Platform as a Service): Platform to develop apps
Ex: Azure App Services, Heroku

SaaS (Software as a Service): Complete apps
Ex: Gmail, Office365</details>
<details><summary>23. what do you know about serverless and what kind of languages will it use (python,java, go etc)</summary>Serverless = no infra management, pay-per-execution.
Runs in response to events.

Languages supported: Python, Node.js, Go, Java, C#

Ex: AWS Lambda, Azure Functions</details>
<details><summary>24. which of the deployment models have downtime and if it is having downtime why we need them ?</summary>Recreate â€“ Yes, due to stopping old pods first

RollingUpdate â€“ No downtime if maxUnavailable=0

Blue-Green/Canary â€“ No downtime if routing is smooth

Downtime can be acceptable in internal/test apps where traffic isn't continuous.</details>
<details><summary>25. what is helm</summary>Helm is the package manager for Kubernetes.
Like apt for Ubuntu or yum for CentOS, but for K8s apps.

Uses Charts (templated YAML files) for deploying apps with parameters.

</details>
<details><summary>26. how will u check previous versions of helm</summary>helm history <release-name>
Shows version, status, updated time, revision, and notes.

</details>
<details><summary>27. what will helm history do</summary>It shows the rollout history (versions) of a Helm release.
You can rollback to a previous revision if needed:

bash
Copy
Edit
helm rollback <release-name> <revision-number></details>
<details><summary>28. Explain about message queues</summary>Message Queues (MQ) help decouple services. Producers send messages; consumers read them asynchronously.

Used for:

Retry mechanisms

Load buffering

Async processing

Examples:

RabbitMQ

Kafka

Azure Service Bus

AWS SQS</details>
    



Feedback : It doesn't matter how much you know, how much you are answering matters
           you know each and every concept but you don't know how to apply it
           You should be having thorough troubleshooting skills
           Needs to have good networking knowledge, you are lacking even basics
           You must know whatever u mentioned in the resume
           you have to know about scripting
           
